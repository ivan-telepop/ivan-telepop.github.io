---
title: "Ollama на Intel Core i7 - Вызов функций с помощью AI  "
publishedAt: "2025-04-20"
summary: "LLM на localhost"
tags: "ollama,python,tool_calls,function calls"
---



Представьте, что у вас есть чат для общения с клиентами в Telegram, WhatsApp или на сайте. В нем ваши потенциальные клиенты общаются с нейронкой ИИ продавцом.

Люди пишут ему (напрмер): 

«Хочу купить 3 пачки гвоздей и 2 игрушки для любимой кошки ! Расскажите про гвозди..!». 
Нейрпонный ИИ ассистент-продажник сам вызывает нужную функцию, создает заказ, считает суммы, "выкатывает" счет — всё без участия человека! 
Или, например, бухгалтер задаёт вопрос: «Сколько нужно доплатить, если я уже отдала 10000, а мы вам должены были 13200?».
ИИ ассистент моментально даёт ответ... А бонусом в случае необходимости высылает счет, накладную или что там еще нужно для отчетов и оплаты в вашем бизнесе..?
Это и есть tool calls (function calling) — когда искусственный интеллект не просто разговаривает с клиентами, а сам инициирует выполнение нужных действий. 
В любом бизнесе много таких действий (функций), как правило почти все они могут быть реализованы программно на языке программирования. 
Выслать письмо, создать pdf документ, накладную, сделать звонок кому-то, снимок чего либо, измерить что либо.
Как правило это просто функции которые можно вызывать в на компьютере. Все зависит от бизнес процессов и фантазии разработчика который решил автоматизировать бизнес процессы. 
Я уже делал подобное на API open.ai, но заставить целиком работать подобное приложение у себя на компьютере еще не пробовал. Только используя внешние вспомогательные сервисы и рессурсы.
На этот раз я решил попробовать запустив ИИ Ollama на своём MacBook, настроить его так чтоб он анлизировал всю поступающую из чатов текстовую информацию,
и реагировать на текст как это обычно делают люди.

### Что такое Ollama?


Ollama — это среда, песочница или простой способ запускать локальные языковые модели (типа ChatGPT) прямо у себя на компьютере. 
Не нужно никаких серверов или облаков — всё работает у вас на ПК на родном потрепаном ноутбуке с частичками еды в клавиатуре. 
Удобно, особенно если хочется быстро поэкспериментировать, и не возится разбираясь с VDS/VPS ssh, RDP и еще чем то непонятным.
Я работал на чикен-МакБуке, но все это делается на любой ОС из тех что вам знакомы (Linux,Mac,Windows)! 


#### Установка Ollama:


Открываем Terminal и пишем такую команду:

```
curl -fsSL https://ollama.com/install.sh | sh
```
Запустил нужную модель (я выбрал Llama 3.2):

```
ollama run llama3.2

```

Инициировал проект с помощью пакетного менеджера uv.  
Установил Python-библиотеку для работы с Ollama:

```
uv pip install ollama
```
#### Простой пример tool calls

Теперь — самая интересная часть. Я написал небольшой код, который подключает две простые функции: сложение и вычитание. 
Как я говорил ранее, функции могут быть абсолютно любые ! В качестве очень простого примера я написал две: "сладывалка чисел", "вычиталка чисел".
А на вход функциям даются аргументы которые ИИ ассистент должен извлекать из текста сообщения.
Я дал модели понять, когда именно можно их использовать, описав свои требования в системном prompt (description).
Функции очень простые, чисто для эксперимента. В реальном проекте они могут быть какие угодно. 
Это уже вопрос вашей фантазии и нужд вашего бизнеса.

Вот сам код:
```

from ollama import ChatResponse, chat

# Рабочий пример функций для вызова tool calls
def add_two_numbers(a: int, b: int) -> int:
  """Сложение аргументов a: int  b: int """  
  return int(a) + int(b)

def subtract_two_numbers(a: int, b: int) -> int:
"""Деление аргументов a: int  b: int """
  return int(a) - int(b)

# Описание доступных инструментов
subtract_two_numbers_tool = {
  'type': 'function',
  'function': {
    'name': 'subtract_two_numbers',
    'description': 'Вычитает одно целое число из другого. Используй эту функцию только в том случае, если пользователь явно просит вычесть два числа или вычислить разницу.',
    'parameters': {
      'type': 'object',
      'required': ['a', 'b'],
      'properties': {
        'a': {'type': 'integer', 'description': 'The first number'},
        'b': {'type': 'integer', 'description': 'The second number'},
      },
    },
  },
}

add_two_numbers_tool = {
  'type': 'function',
  'function': {
    'name': 'add_two_numbers',
    'description': 'Performs simple addition only when the user explicitly asks to add or sum two integers.',
    'parameters': {
      'type': 'object',
      'required': ['a', 'b'],
      'properties': {
        'a': {'type': 'integer', 'description': 'The first number to be added.'},
        'b': {'type': 'integer', 'description': 'The second number to be added.'},
      },
    },
  },
}

all_tools = dict()
all_tools.update(subtract_two_numbers_tool)
all_tools.update(add_two_numbers_tool)

# Пример общения с моделью
messages = [
    {"role": "system", "content": "Only use tools when the user clearly asks for a specific arithmetic operation (addition or subtraction). Do not call tools unless the intent is explicitly stated."},
    # Пример очень простого вопроса к боту
    {'role': 'user', 'content': 'Сколько будет семь умножить на двенадцать ?'}
]

available_functions = {
  'add_two_numbers': add_two_numbers,
  'subtract_two_numbers': subtract_two_numbers,
}

response: ChatResponse = chat(
  'llama3.2',
  messages=messages,
  tools=[all_tools],
  stream=False,
)

if response.message.tool_calls:
  for tool in response.message.tool_calls:
    if function_to_call := available_functions.get(tool.function.name):
      print('Вызвана функция:', tool.function.name)
      print('Аргументы функции:', tool.function.arguments)
      output = function_to_call(**tool.function.arguments)
      print('Вывод:', output)
    else:
      print('Вызываемая функция', tool.function.name, 'не найдена')

```

Когда я запустил этот скрипт, модель правильно поняла: «Семь умножить на двенадцать» — это команда на сложение. Она сама вызвала нужную функцию и выдала ответ. Всё без моего участия.

#### Итог:
Технология рабочая ! ИИ анализирует входящий текст, извлекает числовые аргументы из текста сообщений, запускает функции если ситуация соответствует критериям и требованиям в моем задании!
Теперь можно расширять этот подход: 
например подключить функции для создания счетов, генерации PDF-документов, искать товары в базе данных, работать с базой данных — всё это будет инициироваться нейронным работником, обычным человеческим языком.
Такой вот эксперимент... Чуть позже разовью идею !

[Ollama docs:](https://ollama.com/blog/tool-support)